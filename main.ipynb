{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG-LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI \n",
    "\n",
    "from src.utils import *\n",
    "from src.data_utils import SQLDBManager, Neo4jGraphManager\n",
    "from src.tools import GraphQueryAgent, SQLQueryAgent\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_azure_openai(api_base='https://azsdc-openai-33.openai.azure.com/', api_version='2023-07-01-preview')    # setup azure openai AD token\n",
    "llm_version = 'gpt-4'   # gpt-4, gpt-35-turbo\n",
    "llm = AzureChatOpenAI(model=llm_version, max_tokens=2000, temperature=0)    # instantiate llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare & init DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_version = 'gpt-4'   # gpt-4, gpt-35-turbo\n",
    "# llm = AzureChatOpenAI(model=llm_version, max_tokens=1000, temperature=0)    # instantiate llm\n",
    "# set db variables\n",
    "# src_table = 'pegadata.ppm_work'\n",
    "# req_cols_path = 'data/pega-as-clone/req_fields.txt'\n",
    "# data_table = f'{src_table}_filtered'\n",
    "# primary_key = 'pyid'\n",
    "\n",
    "# dbm = SQLDBManager.from_env()  # instantiate SQLDBManager\n",
    "# filter data table and create new\n",
    "# dbm.filter_table(src_table, req_cols_path, primary_key, overwrite=True)\n",
    "\n",
    "# drop cols\n",
    "# cols_to_drop = ...\n",
    "# dbm.drop_cols(data_table, cols_to_drop)\n",
    "\n",
    "# clean html\n",
    "# text_col = 'pydescription'\n",
    "# dbm.clean_html(data_table, [text_col], primary_key) # clean html\n",
    "\n",
    "# create embeddings\n",
    "# dbm.embed_objs(f'{schema}.{table}', cols_to_embed=['pylabel', 'description'], pk='pyid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL-RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'pegadata'\n",
    "table = 'ppm_work_filtered' \n",
    "dbm = SQLDBManager.from_env(schema=schema, include_tables=[table])   # instantiate SQLDBManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent with tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use agent w tools to query graph\n",
    "dqa = SQLQueryAgent(dbm.db, llm)    # instantiate db query agent\n",
    "\n",
    "# run queries\n",
    "query = \"who in charge of the user story about end-to-end testing of GenAI services?\"\n",
    "print(f\"user query: {query}\")\n",
    "result = dqa.run(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval on test set\n",
    "test_queries_path = 'data/sample_queries.csv'\n",
    "df_queries = pd.read_csv(test_queries_path, sep=';', index_col='id')\n",
    "responses = {}\n",
    "dqa = SQLQueryAgent(dbm.db, llm)    # instantiate db query agent\n",
    "\n",
    "# iter thru queries and generate responses\n",
    "for qid, row in df_queries.iterrows():\n",
    "    query = row['query']\n",
    "    print(f\"running query {qid}: {query}\")\n",
    "    try:\n",
    "        result = dqa.run(query=query)\n",
    "        responses[qid] = result\n",
    "    except Exception as e:\n",
    "        print(f\"error: {e}\")\n",
    "    print('\\n')\n",
    "    \n",
    "# save responses to csv\n",
    "df_responses = pd.DataFrame.from_dict(responses, orient='index', columns=['response'])\n",
    "responses_path = f'outputs/sql-rag/responses_{llm_version}.csv'\n",
    "os.makedirs(os.path.dirname(responses_path), exist_ok=True)\n",
    "with open(responses_path, 'w') as f:\n",
    "    df_responses.to_csv(f, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy of responses\n",
    "responses_eval_path = f'outputs/sql-rag/responses_{llm_version}_eval.csv'\n",
    "results_path = f'outputs/sql-rag/results_{llm_version}.json'\n",
    "eval_res = eval_rag_responses(responses_eval_path, results_path)\n",
    "for metric, val in eval_res.items():\n",
    "    print(f\"{metric}: {val:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KG-RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngm = Neo4jGraphManager.from_env()  # instantiate neo4j graph manager\n",
    "schema = 'pegadata'\n",
    "table = 'ppm_work_filtered'\n",
    "# ngm.from_table(f'{schema}.{table}', reset=True)    # create graph from table\n",
    "# ngm.graph.refresh_schema()\n",
    "# print(f\"graph schema:\\n{ngm.graph.schema}\")\n",
    "\n",
    "# embed graph objects\n",
    "# ngm.embed_objs() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent with tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use agent w tools to query graph\n",
    "gqa = GraphQueryAgent(ngm.graph, llm)    # instantiate graph query agent\n",
    "\n",
    "# single query\n",
    "# query = \"how many user stories are there in total?\"\n",
    "query = \"who in charge of the user story about end-to-end testing of GenAI services?\"\n",
    "print(f\"user query: {query}\")\n",
    "gqa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval on test set\n",
    "test_queries_path = 'data/sample_queries.csv'\n",
    "df_queries = pd.read_csv(test_queries_path, sep=';', index_col='id')\n",
    "responses = {}\n",
    "\n",
    "gqa = GraphQueryAgent(ngm.graph, llm)    # instantiate graph query agent\n",
    "\n",
    "# iter thru queries and generate responses\n",
    "for qid, row in df_queries.iterrows():\n",
    "    query = row['query']\n",
    "    print(f\"user query: {query}\")\n",
    "    try:\n",
    "        result = gqa.run(query)\n",
    "        responses[qid] = result\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"error: {e}\")\n",
    "    print('\\n')\n",
    "\n",
    "# save responses to csv\n",
    "df_responses = pd.DataFrame.from_dict(responses, orient='index', columns=['response'])\n",
    "responses_path = f'outputs/kg-rag/responses_{llm_version}.csv'\n",
    "os.makedirs(os.path.dirname(responses_path), exist_ok=True)\n",
    "df_responses.head()\n",
    "# with open(responses_path, 'w') as f:\n",
    "#     df_responses.to_csv(f, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy of responses\n",
    "responses_eval_path = f'outputs/kg-rag/responses_{llm_version}_eval.csv'\n",
    "results_path = f'outputs/kg-rag/results_{llm_version}.json'\n",
    "eval_res = eval_rag_responses(responses_eval_path, results_path)\n",
    "for metric, val in eval_res.items():\n",
    "    print(f\"{metric}: {val:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
