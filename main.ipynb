{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG-LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "from src.utils import setup_azure_openai\n",
    "from src.data_utils import SQLDBManager\n",
    "from sql_pgvector.chain_utils import RAGChainManager\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully setup Azure OpenAI authentication\n"
     ]
    }
   ],
   "source": [
    "# setup azure openai AD token\n",
    "setup_azure_openai()\n",
    "# print(f\"AD token set: {os.environ['AZURE_OPENAI_AD_TOKEN']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare & init DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to database successfully.\n"
     ]
    }
   ],
   "source": [
    "# set db variables\n",
    "# src_table = 'pegadata.ppm_work'\n",
    "# req_cols_path = 'data/pega-as-clone/req_fields.txt'\n",
    "# data_table = f'{src_table}_filtered'\n",
    "# primary_key = 'pxinsname'\n",
    "# text_col = 'pydescription'\n",
    "# instantiate sql db manager & connect to sql db\n",
    "# dbm = SQLDBManager.from_env()\n",
    "\n",
    "# filter 'ppm_work' table and create new (if not exists) \n",
    "# sqldb_manager.filter_table(src_table, req_cols_path, primary_key)\n",
    "# clean text in 'pydescription' before creating embs\n",
    "# sqldb_manager.clean_html(data_table, [text_col], primary_key)\n",
    "\n",
    "# create embeddings\n",
    "# embs_model = AzureOpenAIEmbeddings(azure_deployment=\"text-embedding-ada-002\") # instantiate embeddings model\n",
    "# sqldb_manager.create_embs_col(data_table, text_col, embs_model) # create embeddings col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! stop is not default parameter.\n",
      "                    stop was transferred to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to database successfully.\n",
      "query: find the most recent user story under epic 4 and summarize it\n",
      "\n",
      "sql query: SELECT \"pxinsname\", \"pydescription\" FROM \"ppm_work_filtered\" WHERE \"epicid\" = 'EPIC-4' AND \"pxobjclass\" = 'PegaProjMgmt-Work-UserStory' ORDER BY \"pxcreatedatetime\" DESC LIMIT 1\n",
      "\n",
      "response: The most recent user story related to the EPIC-4 epic is named \"US-10\". Its description is \"As SRT I would like to have mapping stored in cpsetting updated and pointing to correct API management in Production Adoption and Production account.\"\n"
     ]
    }
   ],
   "source": [
    "# generate sql query to fetch data from db\n",
    "dbm = SQLDBManager.from_env()   # instantiate sql db manager\n",
    "embs_model = AzureOpenAIEmbeddings(azure_deployment=\"text-embedding-ada-002\") # instantiate embeddings model\n",
    "llm = AzureChatOpenAI(model='gpt-35-turbo', max_tokens=500, temperature=0.9, stop=[\"\\nSQLResult:\"])  # instantiate lm\n",
    "rcm = RAGChainManager(dbm.db, llm, embs_model)   # instantiate rag chain manager\n",
    "\n",
    "# generate sql query\n",
    "# user_query = \"how many user stories are under epic 4?\"\n",
    "user_query = \"find the most recent user story under epic 4 and summarize it\"\n",
    "# sql_query = rcm.gen_query(user_query)\n",
    "# print(f\"query: {user_query}\\ngenerated sql query: {sql_query}\") \n",
    "\n",
    "# generate response using rag\n",
    "sql_query, response = rcm.gen_response(user_query)\n",
    "print(f\"query: {user_query}\\n\\nsql query: {sql_query}\\n\\nresponse: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
