{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG-LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from ast import literal_eval\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "from src.utils import *\n",
    "from src.data_utils import SQLDBManager, Neo4jGraphManager\n",
    "from sql_pgvector.chain_utils import RAGChainManager\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load env vars\n",
    "host, port, db, user, password = load_postgres_env_variables()\n",
    "# dbm = SQLDBManager.from_env()   # instantiate SQLDBManager\n",
    "# setup_azure_openai()    # setup azure openai AD token\n",
    "# print(f\"AD token set: {os.environ['AZURE_OPENAI_AD_TOKEN']}\")\n",
    "table = 'pegadata.ppm_work_filtered'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare & init DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to database successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set db variables\n",
    "# src_table = 'pegadata.ppm_work'\n",
    "# req_cols_path = 'data/pega-as-clone/req_fields.txt'\n",
    "# data_table = f'{src_table}_filtered'\n",
    "# primary_key = 'pxinsname'\n",
    "# text_col = 'pydescription'\n",
    "# instantiate sql db manager & connect to sql db\n",
    "# dbm = SQLDBManager.from_env()\n",
    "\n",
    "# filter 'ppm_work' table and create new (if not exists) \n",
    "# sqldb_manager.filter_table(src_table, req_cols_path, primary_key)\n",
    "# clean text in 'pydescription' before creating embs\n",
    "# sqldb_manager.clean_html(data_table, [text_col], primary_key)\n",
    "\n",
    "# copy ppm_work_filtered table to 'public' schema\n",
    "# copy_table_query = f'''CREATE TABLE public.ppm_work_filtered AS\n",
    "# SELECT * FROM pegadata.ppm_work_filtered;'''\n",
    "# dbm.db.run(copy_table_query)\n",
    "\n",
    "# create embeddings\n",
    "# embs_model = AzureOpenAIEmbeddings(azure_deployment=\"text-embedding-ada-002\") # instantiate embeddings model\n",
    "# sqldb_manager.create_embs_col(data_table, text_col, embs_model) # create embeddings col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to database successfully.\n"
     ]
    }
   ],
   "source": [
    "# instantiate llm & db chain\n",
    "# dbm = SQLDBManager.from_env()\n",
    "# llm = AzureChatOpenAI(model='gpt-35-turbo', max_tokens=500, temperature=0.9)\n",
    "# db_chain = SQLDatabaseChain.from_llm(llm, dbm.db, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate embs model, llm, and rag chain manager\n",
    "embs_model = AzureOpenAIEmbeddings(azure_deployment=\"text-embedding-ada-002\") # instantiate embeddings model\n",
    "llm = AzureChatOpenAI(model='gpt-35-turbo', max_tokens=500, temperature=0.9, model_kwargs={\"stop\":[\"\\nSQLResult:\"]})  # instantiate lm\n",
    "rcm = RAGChainManager(dbm.db, llm, embs_model)   # instantiate rag chain manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: list all user stories with deadlines before Feb 1, 2024, along w their assignees and status\n",
      "\n",
      "sql query: SELECT \"pxinsname\", \"pyoriguserid\", \"pystatuswork\" FROM \"ppm_work_filtered\" WHERE \"pxobjclass\" = 'PegaProjMgmt-Work-UserStory' AND \"pysladeadline\" < date '2024-02-01' LIMIT 5\n",
      "\n",
      "sql query result: [('US-4', 'Administrator', 'Pending-Details'), ('US-6', 'Administrator', 'Pending-Details'), ('US-9', 'Administrator', 'Pending-Details'), ('US-1', 'Administrator', 'Pending-Details'), ('US-10', 'Administrator', 'Pending-Details')]\n",
      "\n",
      "response: The SQL query is selecting the values of \"pxinsname\", \"pyoriguserid\", and \"pystatuswork\" from the \"ppm_work_filtered\" table. It is filtering the results based on the condition that \"pxobjclass\" is equal to 'PegaProjMgmt-Work-UserStory' and \"pysladeadline\" is less than the date '2024-02-01'. The query is limited to returning only 5 rows. The SQL response shows the resulting values for the specified columns: [('US-4', 'Administrator', 'Pending-Details'), ('US-6', 'Administrator', 'Pending-Details'), ('US-9', 'Administrator', 'Pending-Details'), ('US-1', 'Administrator', 'Pending-Details'), ('US-10', 'Administrator', 'Pending-Details')].\n"
     ]
    }
   ],
   "source": [
    "# generate sql query\n",
    "# user_query = \"how many user stories are under epic 4?\"\n",
    "# user_query = \"find the most recent user story under epic 4 and summarize it\"\n",
    "# user_query = \"list all the user stories under epic 4, along w/ their priority (if known) and status\"\n",
    "user_query = \"list all user stories with deadlines before Feb 1, 2024, along w their assignees and status\"\n",
    "# sql_query = rcm.gen_query(user_query)\n",
    "# print(f\"query: {user_query}\\ngenerated sql query: {sql_query}\") \n",
    "\n",
    "# generate response using rag\n",
    "sql_query, response = rcm.gen_response(user_query)\n",
    "query_res = dbm.db.run(sql_query)   # run generated sql query on db \n",
    "print(f\"query: {user_query}\\n\\nsql query: {sql_query}\\n\\nsql query result: {query_res}\\n\\nresponse: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KG-RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create neo4j graph from postgres db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\My Drive\\intern@Pega\\rag-llm\\src\\data_utils.py:245: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "ngm = Neo4jGraphManager.from_env()  # instantiate neo4j graph manager\n",
    "ngm.from_table(table, reset=True)    # create graph from table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
