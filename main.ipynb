{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG-LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from src.utils import *\n",
    "from src.data_utils import SQLDBManager, Neo4jGraphManager\n",
    "from src.prompt_templates import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully setup Azure OpenAI authentication\n"
     ]
    }
   ],
   "source": [
    "# load env vars\n",
    "host, port, db, user, password = load_postgres_env_variables()\n",
    "# dbm = SQLDBManager.from_env()   # instantiate SQLDBManager\n",
    "setup_azure_openai()    # setup azure openai AD token\n",
    "# print(f\"AD token set: {os.environ['AZURE_OPENAI_AD_TOKEN']}\")\n",
    "# table = 'pegadata.ppm_work_filtered'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare & init DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to database\n"
     ]
    }
   ],
   "source": [
    "# set db variables\n",
    "# src_table = 'pegadata.ppm_work'\n",
    "# req_cols_path = 'data/pega-as-clone/req_fields.txt'\n",
    "# data_table = f'{src_table}_filtered'\n",
    "# primary_key = 'pyid'\n",
    "\n",
    "# dbm = SQLDBManager.from_env()  # instantiate SQLDBManager\n",
    "# filter data table and create new\n",
    "# dbm.filter_table(src_table, req_cols_path, primary_key, overwrite=True)\n",
    "\n",
    "# drop cols\n",
    "# cols_to_drop = ...\n",
    "# dbm.drop_cols(data_table, cols_to_drop)\n",
    "\n",
    "# clean html\n",
    "# text_col = 'pydescription'\n",
    "# dbm.clean_html(data_table, [text_col], primary_key) # clean html\n",
    "\n",
    "# # create embeddings\n",
    "# embs_model = AzureOpenAIEmbeddings(azure_deployment=\"text-embedding-ada-002\") # instantiate embeddings model\n",
    "# dbm.create_embs_col(data_table, text_col, embs_model) # create embeddings col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to database\n"
     ]
    }
   ],
   "source": [
    "schema = 'pegadata'\n",
    "table = 'ppm_work_filtered' \n",
    "dbm = SQLDBManager.from_env(schema=schema, include_tables=[table])   # instantiate SQLDBManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "give me all user stories assigned to me (Neil) with priority > 10 which have a deadline after all stories assigned to Stijn.\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT * FROM pegadata.ppm_work_filtered WHERE initialassignee = 'Neil' AND pxurgencywork > 10 AND pysladeadline > (SELECT MAX(pysladeadline) FROM pegadata.ppm_work_filtered WHERE initialassignee = 'Stijn')\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[('BL-1', 'Backlog', 'GenAI Gateway Service Backlog', 'Neil', Decimal('20'), datetime.datetime(2024, 5, 1, 0, 0), 'Active', 'Feature Development', 'PROJ-1', 'PRD-1', 'GOAL-1', None, None, 'GenAI Gateway Service Backlog', datetime.date(2023, 11, 9), None), ('US-11', 'UserStory', 'HFIX on 8.7.5 and 23.1.x', 'Neil', Decimal('30'), datetime.datetime(2024, 4, 11, 0, 0), 'Active', 'Feature Development', 'PROJ-2', 'PRD-2', 'GOAL-2', 'EPIC-2', 'BL-2', 'backport or forward port the solution we delovp for multi part signing of outbound messeages for SOAP service.', datetime.date(2024, 2, 14), None), ('GOAL-1', 'Goal', 'Run GenAI Gateway service on Azure OpenAI ChatGPT', 'Neil', Decimal('30'), datetime.datetime(2024, 5, 1, 0, 0), 'Active', 'Feature Development', 'PROJ-1', 'PRD-1', None, None, None, ' Goal: Grow business by expanding the Pega Cloud portfolio to support Generative AI.  \\n \\u200b \\nVision: TBD', datetime.date(2023, 10, 15), None), ('PROJ-1', 'Project', 'Autopilot & GenAI Services', 'Neil', Decimal('80'), datetime.datetime(2024, 6, 1, 0, 0), 'Active', 'Feature Development', None, None, None, None, 'BL-1', 'Autopilot & GenAI Services', datetime.date(2023, 10, 15), None), ('EPIC-3', 'Epic', 'Restrict Redirections to same domain', 'Neil', Decimal('30'), datetime.datetime(2024, 5, 1, 0, 0), 'Active', 'Feature Development', 'PROJ-2', 'PRD-2', 'GOAL-2', None, 'BL-2', 'Feature:\\n\\nExtension to XSS filter in infinity to sanitize that data is encoded and sent in plain text.\\n\\n\\nBusiness context:\\n\\nThe XSS filter in Infinity (publicapi-methods-xss-filtering) sanitizes sensitive HTML characters in input parameters in order to prevent cross site scripting. The filter...', datetime.date(2024, 1, 12), None), ('EPIC-1', 'Epic', 'GenAI as CloudK Service', 'Neil', Decimal('50'), datetime.datetime(2024, 4, 1, 0, 0), 'Active', 'Feature Development', 'PROJ-1', 'PRD-1', 'GOAL-1', None, 'BL-1', ' As the first MLP, it is required to create CloudK service to redirect requests to Azure. \\n Service should: \\n \\n - redirect requests to the Azure part \\n - log information regarding used tokens as returned from Azure \\n \\n Service should be deployable as an add-on product to the client cluster. ', datetime.date(2023, 11, 1), None)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mThe user stories assigned to Neil with priority greater than 10 and have a deadline after all stories assigned to Stijn are:\n",
      "\n",
      "1. User Story ID: BL-1, Title: GenAI Gateway Service Backlog, Priority: 20, Deadline: 2024-05-01\n",
      "2. User Story ID: US-11, Title: HFIX on 8.7.5 and 23.1.x, Priority: 30, Deadline: 2024-04-11\n",
      "3. User Story ID: GOAL-1, Title: Run GenAI Gateway service on Azure OpenAI ChatGPT, Priority: 30, Deadline: 2024-05-01\n",
      "4. User Story ID: PROJ-1, Title: Autopilot & GenAI Services, Priority: 80, Deadline: 2024-06-01\n",
      "5. User Story ID: EPIC-3, Title: Restrict Redirections to same domain, Priority: 30, Deadline: 2024-05-01\n",
      "6. User Story ID: EPIC-1, Title: GenAI as CloudK Service, Priority: 50, Deadline: 2024-04-01\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The user stories assigned to Neil with priority greater than 10 and have a deadline after all stories assigned to Stijn are:\\n\\n1. User Story ID: BL-1, Title: GenAI Gateway Service Backlog, Priority: 20, Deadline: 2024-05-01\\n2. User Story ID: US-11, Title: HFIX on 8.7.5 and 23.1.x, Priority: 30, Deadline: 2024-04-11\\n3. User Story ID: GOAL-1, Title: Run GenAI Gateway service on Azure OpenAI ChatGPT, Priority: 30, Deadline: 2024-05-01\\n4. User Story ID: PROJ-1, Title: Autopilot & GenAI Services, Priority: 80, Deadline: 2024-06-01\\n5. User Story ID: EPIC-3, Title: Restrict Redirections to same domain, Priority: 30, Deadline: 2024-05-01\\n6. User Story ID: EPIC-1, Title: GenAI as CloudK Service, Priority: 50, Deadline: 2024-04-01'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using sql chain\n",
    "llm = AzureChatOpenAI(model='gpt-4', max_tokens=1000, temperature=0)    # instantiate llm\n",
    "\n",
    "# custom prompt\n",
    "prompt = PromptTemplate(input_variables=[\"input\", \"table_info\"], template=rag_sql_prompt)\n",
    "\n",
    "db_chain = SQLDatabaseChain.from_llm(llm, dbm.db, verbose=True, prompt=prompt)    # instantiate db chain\n",
    "\n",
    "# using sql agent\n",
    "# from langchain.agents import create_sql_agent\n",
    "# from langchain.agents import AgentExecutor\n",
    "# from langchain.agents.agent_types import AgentType\n",
    "# from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "\n",
    "# agent_type = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
    "# toolkit = SQLDatabaseToolkit(dbm.db, llm)\n",
    "# db_agent = create_sql_agent(llm=llm, toolkit=toolkit, agent_type=agent_type, verbose=True)    # instantiate db agent\n",
    "\n",
    "# generate sql query\n",
    "# query = \"how many user stories are under epic 1?\"\n",
    "# query = \"find the most recent user story under epic 1 and summarize it\"\n",
    "# query = \"list all the user stories under epic 1, along w/ their priority (if known) and status\"\n",
    "# query = \"list all user stories with deadlines before Feb 1, 2024, along w their assignees and status\"\n",
    "# query =  \"how many user stories are assigned to each assignee?\"\n",
    "# query = \"which pending user story has the nearest deadline?\"\n",
    "# query = \"how many user stories in the 'Testing' category have been completed?\"\n",
    "# query = \"what is the distribution of user stories across different categories?\"\n",
    "# query = \"how many pending user stories have a priority greater than 30?\"\n",
    "# query = \"which pending user story has the nearest deadline? what is its priority and category? which epic does it belong to? are there any other pending user stories under that epic? if yes, which ones?\"\n",
    "query = \"give me all user stories assigned to me (Neil) with priority > 10 which have a deadline after all stories assigned to Stijn.\"\n",
    "# query = \"given the data in this table, generate 10 questions/queries that could be asked about it. your questions should not be too simple, i.e., they cannot be answered w say, a single lookup operation.\"\n",
    "\n",
    "# generate response using rag\n",
    "table_info = dbm.db.get_table_info([table])\n",
    "db_chain.run(query=query, table_info=table_info)\n",
    "# db_agent.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KG-RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create neo4j graph from postgres db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\My Drive\\intern@Pega\\rag-llm\\src\\data_utils.py:247: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph schema:\n",
      "Node properties are the following:\n",
      "UserStory {backlogid: STRING, pxurgencywork: FLOAT, goalid: STRING, epicid: STRING, projectid: STRING, productid: STRING, pydescription_clean: STRING, pysladeadline: LOCAL_DATE_TIME, pystatuswork: STRING, pylabel: STRING, category: STRING, initialassignee: STRING, pyid: STRING, startdate: DATE, pxobjclass: STRING, enddate: DATE},Backlog {goalid: STRING, projectid: STRING, pxurgencywork: FLOAT, pydescription_clean: STRING, pystatuswork: STRING, productid: STRING, category: STRING, pylabel: STRING, pyid: STRING, pysladeadline: LOCAL_DATE_TIME, startdate: DATE, pxobjclass: STRING, initialassignee: STRING},Epic {backlogid: STRING, pxurgencywork: FLOAT, goalid: STRING, productid: STRING, projectid: STRING, pysladeadline: LOCAL_DATE_TIME, pystatuswork: STRING, category: STRING, pyid: STRING, pylabel: STRING, pydescription_clean: STRING, startdate: DATE, pxobjclass: STRING, initialassignee: STRING},Project {pydescription_clean: STRING, pystatuswork: STRING, pxurgencywork: FLOAT, pylabel: STRING, pyid: STRING, pysladeadline: LOCAL_DATE_TIME, category: STRING, startdate: DATE, pxobjclass: STRING, initialassignee: STRING, backlogid: STRING},Goal {projectid: STRING, pxurgencywork: FLOAT, pystatuswork: STRING, productid: STRING, category: STRING, pydescription_clean: STRING, pyid: STRING, pysladeadline: LOCAL_DATE_TIME, startdate: DATE, pxobjclass: STRING, initialassignee: STRING, pylabel: STRING}\n",
      "Relationship properties are the following:\n",
      "\n",
      "The relationships are the following:\n",
      "(:UserStory)-[:IS_STORY_OF_EPIC]->(:Epic),(:Epic)-[:IS_EPIC_OF_GOAL]->(:Goal),(:Goal)-[:IS_GOAL_OF_PROJECT]->(:Project)\n"
     ]
    }
   ],
   "source": [
    "ngm = Neo4jGraphManager.from_env()  # instantiate neo4j graph manager\n",
    "ngm.from_table(f'{schema}.{table}', reset=True)    # create graph from table\n",
    "ngm.graph.refresh_schema()\n",
    "print(f\"graph schema:\\n{ngm.graph.schema}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement KG-RAG using graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query: give me all user stories assigned to me (Neil) with priority > 10 which have a deadline after all stories assigned to Stijn.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (us:UserStory)-[:IS_STORY_OF_EPIC]->(e:Epic)-[:IS_EPIC_OF_GOAL]->(g:Goal)-[:IS_GOAL_OF_PROJECT]->(p:Project)\n",
      "WHERE us.initialassignee = \"Neil\" AND us.pxurgencywork > 10 \n",
      "WITH MAX(us.pysladeadline) AS maxNeilDeadline\n",
      "MATCH (us2:UserStory)\n",
      "WHERE us2.initialassignee = \"Stijn\"\n",
      "WITH MAX(us2.pysladeadline) AS maxStijnDeadline\n",
      "MATCH (us3:UserStory)-[:IS_STORY_OF_EPIC]->(e3:Epic)-[:IS_EPIC_OF_GOAL]->(g3:Goal)-[:IS_GOAL_OF_PROJECT]->(p3:Project)\n",
      "WHERE us3.initialassignee = \"Neil\" AND us3.pxurgencywork > 10 AND us3.pysladeadline > maxStijnDeadline\n",
      "RETURN us3\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'us3': {'goalid': 'GOAL-2', 'pysladeadline': neo4j.time.DateTime(2024, 4, 11, 0, 0, 0, 0), 'productid': 'PRD-2', 'pystatuswork': 'Active', 'initialassignee': 'Neil', 'pxobjclass': 'UserStory', 'startdate': neo4j.time.Date(2024, 2, 14), 'pyid': 'US-11', 'backlogid': 'BL-2', 'epicid': 'EPIC-2', 'pydescription_clean': 'backport or forward port the solution we delovp for multi part signing of outbound messeages for SOAP service.', 'pylabel': 'HFIX on 8.7.5 and 23.1.x', 'category': 'Feature Development', 'pxurgencywork': 30.0, 'projectid': 'PROJ-2'}}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The user story assigned to you, Neil, with priority greater than 10 which has a deadline after all stories assigned to Stijn is 'HFIX on 8.7.5 and 23.1.x'. This user story is currently active and is part of the 'Feature Development' category. The work urgency is 30.0 and the deadline is set for April 11, 2024. The story began on February 14, 2024. The description of the user story is to 'backport or forward port the solution we develop for multi part signing of outbound messages for SOAP service.'\n"
     ]
    }
   ],
   "source": [
    "# generate response using kg rag\n",
    "llm = AzureChatOpenAI(model='gpt-4', max_tokens=1000, temperature=0.5)    # instantiate llm\n",
    "\n",
    "# query = \"how many user stories are under epic 1?\"\n",
    "# query = \"find the most recent user story under epic 1 and summarize it\"\n",
    "# query = \"list all the user stories under epic 1, along w/ their priority (if known) and status\"\n",
    "# query = \"list all user stories with deadlines before Feb 1, 2024, along w their assignees and status\"\n",
    "# query = \"which pending user story has the nearest deadline? what is its priority and category? which epic does it belong to? are there any other pending user stories under that epic? if yes, which ones?\"\n",
    "query = \"give me all user stories assigned to me (Neil) with priority > 10 which have a deadline after all stories assigned to Stijn.\"\n",
    "print(f\"user query: {query}\")\n",
    "\n",
    "prompt_template = kg_rag_prompt\n",
    "prompt = PromptTemplate(input_variables=[\"schema\", \"question\"], template=kg_rag_prompt)   # construct prompt\n",
    "\n",
    "kg_rag_chain = GraphCypherQAChain.from_llm(llm, graph=ngm.graph, cypher_prompt=prompt, verbose=True)   # instantiate kg rag chain\n",
    "\n",
    "response = kg_rag_chain.run(query)  # generate response\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
